
numero di bigrammi, trigrammi, monogrammi  (ovvero, fissato un ngramma, vedere se l'altro ce l'ha) ***
(come con function words: Style based Authorship Attribution on English Editorial Documents, V. et Al.)

-> We filtered out the least frequent n-grams and used the rest as features 
(A Straightforward Author Profiling Approach in MapReduce, Maharjan et Al.)


test su cluster:
almeno 6 reducer su es short input

###################################################################################################

CREAZIONE IMPRONTA AUTORE (O PROFILO AUTORE)

	INPUT:

	Tutti i file.txt;
	Ogni file ha come nome:
	-> author,___,title.txt

	MAP:
		Per ogni file, raccoglie le informazioni volute.
		Estrapola il nome dell'autore dal nome del file stesso.
		Fondamentalmente, 3 calcoli: wordCount, 2-grams, 3-grams.
		Utilizza un in-memory combiner.
		
	PARTITIONER:
		Per ogni file, viene estratto il campo del nome dell'autore.
		In base al nome dell'autore, verrà selezionato un reducer.
		n = numero autori; r = numero reducer.
		r >= n ---> ogni reducer si occupa di un autore; le informazioni relative
					a quell'autore (nel calcolo percentuale) è preservata.
		r < n  ---> ERRORE; se i reducer indicati non sono sufficienti,
					verranno indicati stessi reducer per autori diversi 
					(rispettivamente al modulo; se ci sono 6 autori e vengono indicati 4 reducer,
					6 % 4 = 2, i primi due reducer ricevono ognuno 2 autori diversi);
					pertanto i risultati saranno falsati.

	REDUCE:
		Riceve i calcoli di ogni libro dello stesso autore.
		Somma i valori e calcola i valori percentuale.
		Genererà così una serie di valori che saranno l'impronta dell'autore.
		
	OUTPUT:
	
	Un file per ogni autore.
	Ogni file ha come nome:
	-> nome_autore.rdddddd
	
DEDUZIONE AUTORE

	INPUT
	
	Uno o più file di testo di cui l'autore non è conosciuto.
	Rimozione delle prime ~50 righe in cui, per conformazione del progetto Gutenberg,
	è possibile la presenza del nome dell'autore, al fine di non falsare la ricerca dell'autore.
	Caricamento valori estratti in distributed cache.
	
	Chiamata al Job di creazione impronta.
	
	MAP(1):
		Caricamento impronta in strutture globali.
		
	MAP:
		Calcolo percentuale di somiglianza.
		Ogni map confronta un'impronta nota con l'impronta sconosciuta	
	
	REDUCE (1):
		Riceve tutti i risultati dei confronti ed emette una lista ordinata
		di somiglianza.
		
	OUTPUT
		Un file con una lista ordinata per punteggio di somiglianza;
		Per ogni autore, il punteggio di somiglianza.
		
###################################################################################################

PREPARAZIONE DEI FILE DI INPUT

FATTO

###################################################################################################

CREAZIONE IMPRONTA

Nella creazione dell'impronta di un autore, ovvero del profiling di un autore in esame,
ho preso in considerazione:
- la lunghezza media delle frasi nelle opere dell'autore in esame (line length) (non utilizzato);
- la lunghezza media delle parole utilizzate dall'autore (word length);
- la ricchezza del vocabolario (vocabulary richness), andando a guardare:
	- hapaxlegomena, ovvero parole che compaiono una volta soltanto in ogni testo;
	- hapaxdislegomena, ovvero parole che compaiono due volte soltanto in ogni testo;
	- il numero di parole uniche utilizzate e loro frequenza;
- 2-grams, ovvero la vicinanza(*) di due parole;
- 3-grams;
- densità(*) delle "function words", ovvero 150 parole uniche (preposizioni, articolazioni, etc.);
- densità della punteggiatura, ovvero { . , ? ! " ( ) - : ; } ;

(*)
- Il concetto di vicinanza può essere:
	- parole a sinistra e a destra di ogni parola (contigue);
	- parole che in generale compaiono nella stessa frase;
	Ho scelto come concetto di vicinanza le parole contigue alla parola in esame, ovvero la parola in esame
	e la sua successiva.
- Con densità si intende il rapporto tra la data parola o simbolo e il numero totale di parole o simboli analizzati 
	(ovvero, sia x la parola da analizzare, x/token_total.size)

(Da word_count: word_length, 1_word, 2_word, punctuation_density, function_word_density, word_frequency)
(Da analisi vicinanza: 2_gram, 3_gram)
DA AGGIORNARE CON TTR
1. line_length (non utilizzato);
2. word_length_avg;
3. 1_word;
4. 2_word;
5. 2_gram;
6. 3_gram;
7. punctuation_density;
8. function_word_density;
9. word_frequency (tra le 20 - 60 più utilizzate);


###################################################################################################

SCELTE PROGETTUALI

FATTO

Considerazioni:

FATTO (solo da qui)

###################################################################################################

ALTRO

Function words (150):
a, between, in, nor, some, upon, about, both, including, nothing, somebody, us, above, but, inside, of, someone, 
used, after, by, into, off, something, via, all, can, is, on, such, we, although, coos, it, once, than, what, am, 
do, its, one, that, whatever, among, down, latter, onto, the, when, an, each, less,  opposite, their, where, and, 
either, like, or, them, whether, another, enough, little, our, these, which, any, every, lots, outside, they, 
while, anybody,  everybody, many, over, this, who, anyone, everyone, me, own, those, whoever, anything, everything, 
more, past, though, whom, are, few, most, per, though,  whose, around, following, much, plenty, till, will, as, 
for, must, plus, to, with, at, from, my, regarding, toward, within, be, have, near, same, towards,  without, 
because, he, need, several, under, worth, before, her, neither, she, unless, would, behind, him, no, should, 
unlike, yes, below, I, nobody, since, until, you, beside, if, none.
Function words (150, formatted):
"a", "between", "in", "nor", "some", "upon", "about", "both",
"including", "nothing", "somebody", "us", "above", "but", "inside",
"of", "someone", "used", "after", "by", "into", "off", "something",
"via", "all", "can", "is", "on", "such", "we", "although", "coos", "it",
"once", "than", "what", "am", "do", "its", "one", "that", "whatever", "among",
"down", "latter", "onto", "the", "when", "an", "each", "less",
"opposite", "their", "where", "and", "either", "like", "or", "them", "whether",
"another", "enough", "little", "our", "these", "which", "any", "every", "lots", "outside",
"they", "while", "anybody", "everybody", "many", "over", "this", "who", "anyone",
"everyone", "me", "own", "those", "whoever", "anything", "everything", "more", "past",
"though", "whom", "are", "few", "most", "per", "though", "whose", "around", "following", 
"much", "plenty", "till", "will", "as", "for", "must", "plus", "to", "with", "at", 
"from", "my", "regarding", "toward", "within", "be", "have", "near", "same", "towards",
"without", "because", "he", "need", "several", "under", "worth", "before", "her",
"neither", "she", "unless", "would", "behind", "him", "no", "should", "unlike", "yes",
"below", "I", "nobody", "since", "until", "you", "beside", "if", "none".


