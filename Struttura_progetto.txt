	SHUFFLING PHASES



###################################################################################################

CREAZIONE IMPRONTA AUTORE (O PROFILO AUTORE)

	INPUT:

	Tutti i file.txt;
	Ogni file ha come nome:
	-> author,___,title.txt

	MAP:
		Per ogni file, raccoglie le informazioni volute.
		Estrapola il nome dell'autore dal nome del file stesso.
		Fondamentalmente, 3 calcoli: wordCount, 2-grams, 3-grams.
		Utilizza un in-memory combiner.
		
	PARTITIONER:
		Per ogni file, viene estratto il campo del nome dell'autore.
		In base al nome dell'autore, verrà selezionato un reducer.
		n = numero autori; r = numero reducer.
		r >= n ---> ogni reducer si occupa di un autore; le informazioni relative
					a quell'autore (nel calcolo percentuale) è preservata.
		r < n  ---> ERRORE; se i reducer indicati non sono sufficienti,
					verranno indicati stessi reducer per autori diversi 
					(rispettivamente al modulo; se ci sono 6 autori e vengono indicati 4 reducer,
					6 % 4 = 2, i primi due reducer ricevono ognuno 2 autori diversi);
					pertanto i risultati saranno falsati.

	REDUCE:
		Riceve i calcoli di ogni libro dello stesso autore.
		Somma i valori e calcola i valori percentuale.
		Genererà così una serie di valori che saranno l'impronta dell'autore.
		
	OUTPUT:
	
	Un file per ogni autore.
	Ogni file ha come nome:
	-> nome_autore.rdddddd
	
DEDUZIONE AUTORE

	INPUT
	
	Uno o più file di testo di cui l'autore non è conosciuto.
	Rimozione delle prime ~50 righe in cui, per conformazione del progetto Gutenberg,
	è possibile la presenza del nome dell'autore, al fine di non falsare la ricerca dell'autore.
	Caricamento valori estratti in distributed cache.
	
	Chiamata al Job di creazione impronta.
	
	MAP(1):
		Caricamento impronta in strutture globali.
		
	MAP:
		Calcolo percentuale di somiglianza.
		Ogni map confronta un'impronta nota con l'impronta sconosciuta	
	
	REDUCE (1):
		Riceve tutti i risultati dei confronti ed emette una lista ordinata
		di somiglianza.
		
	OUTPUT
		Un file con una lista ordinata per punteggio di somiglianza;
		Per ogni autore, il punteggio di somiglianza.
		
###################################################################################################

PREPARAZIONE DEI FILE DI INPUT

Fase di download dei dati;
pulizia dati, ovvero organizzazione per autore ed estrazione di circa il 10% dei dati per essere usati come test.
Lo script crawler dei dati dal sito project Gutenberg scarica tutti i file txt di lingua inglese.
Per convenzione del project Gutenberg, i file txt sono nominati in modo non-userfriendly 
(dal libro numero 10000 in poi, il nome del file è il numero stesso del file; 
per i primi 100000, la name convention utilizzata è una abbreviazione di qualche tipo del titolo del libro); 
allo scopo di avere le basi per poter sviluppare il suddetto progetto (ovvero conoscere l'autore),
 ho creato uno script che rinominasse tutti i file di testo con autore + titolo (author,___,title).
Inoltre, i file dezippati non sono sempre il file txt, ma cartelle con all'interno il file txt in questione; ho estratto tali file
e rimosso la cartella ora vuota.
 Siccome la maggioranza dei file ha, tra le prime 30 righe, una riga del formato "Author: nome" e "Title: titolo", 
 ho estratto tali campi e li ho utilizzati per rinominare i file;
inoltre ho creato una cartella per autore e spostato i file relativi a quell'autore nella sua cartella.
Lo script fallisce nei casi in cui o nel nome dell'autore o nel titolo vengono utilizzati caratteri non codificati da UTF-8, o nel
caso in cui nel nome o nel titolo viene utilizzato il carattere / (nello spostare i file in modo automatico, legge quel carattere
come se ci fosse una subdirectory, fallendo la mv del file), o nel caso nel titolo sia presente il carattere ":"; HDFS non permette
di trasferire file con tale carattere nel nome.
I file che non hanno la stringa Author: X o Title: X sono stati spostati in una cartella a parte chiamata "00000_AUTHOR_NOT_FOUND".
I rimanenti file di testo sono stati spostati nella cartella "00001_NAMING_ERROR".
Ho manualmente eseguito il merge delle cartelle degli autori E. A. Poe, A. C. Doyle, Dostoevskij, Arthur Quiller-Couch, Tolstoj, 
Alexandre Dumas (pere e fils), Charlotte Bronte, Thomas De Quincey, A. F. Mockler Ferryman, Gordon Stables, Charles Egbert Craddock.
Ho eseguito il conteggio dei file per ogni autore e salvato l'output nel file count.txt.
I file di input nel progetto MapReduce non possono essere cartelle, quindi i file txt degli autori selezionati per lo studio
 sono stati estratti di nuovo dalle cartelle; i file di input potrebbero essere letti dalle cartelle se al HFDS venisse indicato
 di leggere in modo ricorsivo nel path input, ma non è un'operazione necessaria.
Nello sviluppo del progetto, ho quindi ignorato i file con una name convention non conforme al mio script di ordinamento;
nella creazione delle impronte, ho ignorato gli autori con un solo libro come opera;
nella ricerca dell'autore, ho utilizzato un sottoinsieme degli autori così rimasti.

###################################################################################################

CREAZIONE IMPRONTA

Nella creazione dell'impronta di un autore, ovvero del profiling di un autore in esame,
ho preso in considerazione:
- la lunghezza media delle frasi nelle opere dell'autore in esame (line length) (non utilizzato);
- la lunghezza media delle parole utilizzate dall'autore (word length);
- la ricchezza del vocabolario (vocabulary richness), andando a guardare:
	- hapaxlegomena, ovvero parole che compaiono una volta soltanto in ogni testo;
	- hapaxdislegomena, ovvero parole che compaiono due volte soltanto in ogni testo;
	- il numero di parole uniche utilizzate e loro frequenza;
- 2-grams, ovvero la vicinanza(*) di due parole;
- 3-grams;
- densità(*) delle "function words", ovvero 150 parole uniche (preposizioni, articolazioni, etc.);
- densità della punteggiatura, ovvero { . , ? ! " ( ) - : ; } ;

(*)
- Il concetto di vicinanza può essere:
	- parole a sinistra e a destra di ogni parola (contigue);
	- parole che in generale compaiono nella stessa frase;
	Ho scelto come concetto di vicinanza le parole contigue alla parola in esame, ovvero la parola in esame
	e la sua successiva.
- Con densità si intende il rapporto tra la data parola o simbolo e il numero totale di parole o simboli analizzati 
	(ovvero, sia x la parola da analizzare, x/token_total.size)

(Da word_count: word_length, 1_word, 2_word, punctuation_density, function_word_density, word_frequency)
(Da analisi vicinanza: 2_gram, 3_gram)
1. line_length (non utilizzato);
2. word_length_avg;
3. 1_word;
4. 2_word;
5. 2_gram;
6. 3_gram;
7. punctuation_density;
8. function_word_density;
9. word_frequency (tra le 20 - 60 più utilizzate);

Ognuno dei 9 valori è stato moltiplicato per un peso prima di generare un punteggio di somiglianza.

Weight parameters ipotizzati:
1. line_length, 0.35;
2. word_length, 0.35;
3. 1_word, 0.2;
4. 2_word, 0.25;
5. 2_gram, 0.35;
6. 3_gram, 0.3;
7. punctuation_density, 0.45;
8. function_word_density, 0.5;
9. word_frequency (tra le 20 - 60 più utilizzate), 0.4;
I valori grezzi andranno parametrizzati e poi pesati; dopodichè sommati per andare a generare il punteggio di somiglianza.
Per lo stesso testo, i punteggi dovrebbero essere:
1. 1 * 0.35
2. 1 * 0.35
3. 1 * 0.20
4. 1 * 0.25
5. 1 * 0.35
6. 1 * 0.30
7. 1 * 0.45
8. 1 * 0.50
9. 1 * 0.40
___________________
		tot. = 3.15

###################################################################################################

SCELTE PROGETTUALI

hadoop version
Hadoop 2.6.0-cdh5.7.0
Minimum requirements: JDK 7

1.
A causa dei diversi modi di scrivere il nome dell'autore, uno stesso autore può essere 
indicato in diverso modo, con iniziali puntate, con solo nome puntato, con pseudonimi,
con traduzioni diverse etc. I file di testo avranno nel nome diversi autori indicati,
pertanto verrebbero trattati come autori diversi dal programma MapReduce.
Ho identificato alcuni di questi casi che potrebbero essere utili nel caso studio:
E. A. Poe, A. C. Doyle, Dostoevskij, Arthur Quiller-Couch, Tolstoj, Alexandre Dumas (pere e fils),
 Charlotte Bronte, Thomas De Quincey, Gordon Stables, Charles Egbert Craddock.
 1.1
 Ho utilizzato uno script per scaricare tutti i libri necessari per lo studio. Sono stati utilizzati
i formati txt e la lingua inglese. Data la non interpretazione della semantica, implementare il programma per la lingua
inglese non influenza l'implementazione su dataset di altre lingue. Le uniche note da tenere in considerazione
sono la lingua unica dei libri per autore (non posso avere un'impronta dell'autore X costituita da metà libri in inglese
e metà libri in italiano; sarebbe come avere metà libri a disposizione) e la compatibilità con alfabeti differenti dal latino.
 2.
 Nel calcolo del numero medio di parole utilizzate in una frase, bisognerebbe poter contare
 correttamente le frasi. Siccome la terminazione di una frase è data da caratteri quali punto interrogativo,
 punto escalamtivo, punto fermo, si potrebbero utilizzare tali caratteri come caratteri separatori;
 purtroppo non ho trovato un metodo efficiente per poter separare le frasi grazie al punto.
 Per esempio, se una frase termina col punto, spazio e parola successiva inizia con una maiuscola,
 possono esserci falsi positivi, come "Dott. Zivago"; allo stesso modo, ignorando la maiuscola, 
 possono dare falsi positivi tutte le abbreviazioni "etc.; dott.; sig.;...". Considerando solo il punto,
 potrebbero essere falsi positivi i numeri decimali separati da punto, "3.14$".
 Pertanto escludo questo parametro. 
 3.
 Il calcolo degli n-grams prevede un concetto di vicinanza. Per il punto 2, dobbiamo escludere il concetto
 di vicinanza come parole continue nella frase, in quanto una frase non è ben delimitata.
 Pertanto utilizzo come concetto di vicinanza le parole contigue nella line in analisi.
 Vicinanza in n-grams: https://en.wikipedia.org/wiki/N-gram.
4.
Molti studi di author profiling generano la funzione di identificazione tramite tecniche di intelligenza artificiale.
Non essendo questa implementata nel progetto, il peso delle varie caratteristiche nel determinare l'autore di un testo
sono state scelte manualmente e impostate con alcuni lanci di prova con parametri diversi.
5.
Utilizzo librerie prese dal container installato sul mio computer. Essendo la versione di Cloudera
non aggiornata all'ultima versione di hadoop, nonostante quest'ultima sia compatibile con JDK8, la versione
precedente è compatibile con JDK7, pertanto verrà utilizzata questa versione di Java.
6.
Per la lineDensity, un float è più che sufficiente rispetto al tipo double; tale scelta è inoltre
maggiormente motivata poichè DoubleWritable non funziona correttamente.
7.
Il numero di reducer indicato (nella creazione impronta) deve essere necessariamente 
almeno uguale al numero di autori analizzati; siccome nella creazione delle impronte gli autori sono noti,
lo sarà anche il loro numero. In caso di mancanza di reducer disponibili, si può fare
una pre-selezione degli autori da passare per creare le impronte.
8.
Per poter leggere le strutture utilizzate, le stampo con caratteri speciali per distinguere
ogni valore di ogni struttura:
wordcount:
@parola=valore
couples:
%parola1|parola2=valore
trigrams:
#parola1|parola2|parola3=valore

Escluso:
SVM, sentiment analysis, naive bayes, AI.

Considerazioni:
Verranno tratte le dovute conclusioni relative alle tecniche migliori per il riconoscimento,
per la ricerca stessa ed estrazione delle impronte, della scalabilità del programma.

###################################################################################################

ALTRO

Function words (150):
a, between, in, nor, some, upon, about, both, including, nothing, somebody, us, above, but, inside, of, someone, 
used, after, by, into, off, something, via, all, can, is, on, such, we, although, coos, it, once, than, what, am, 
do, its, one, that, whatever, among, down, latter, onto, the, when, an, each, less,  opposite, their, where, and, 
either, like, or, them, whether, another, enough, little, our, these, which, any, every, lots, outside, they, 
while, anybody,  everybody, many, over, this, who, anyone, everyone, me, own, those, whoever, anything, everything, 
more, past, though, whom, are, few, most, per, though,  whose, around, following, much, plenty, till, will, as, 
for, must, plus, to, with, at, from, my, regarding, toward, within, be, have, near, same, towards,  without, 
because, he, need, several, under, worth, before, her, neither, she, unless, would, behind, him, no, should, 
unlike, yes, below, I, nobody, since, until, you, beside, if, none.
Function words (150, formatted):
"a", "between", "in", "nor", "some", "upon", "about", "both",
"including", "nothing", "somebody", "us", "above", "but", "inside",
"of", "someone", "used", "after", "by", "into", "off", "something",
"via", "all", "can", "is", "on", "such", "we", "although", "coos", "it",
"once", "than", "what", "am", "do", "its", "one", "that", "whatever", "among",
"down", "latter", "onto", "the", "when", "an", "each", "less",
"opposite", "their", "where", "and", "either", "like", "or", "them", "whether",
"another", "enough", "little", "our", "these", "which", "any", "every", "lots", "outside",
"they", "while", "anybody", "everybody", "many", "over", "this", "who", "anyone",
"everyone", "me", "own", "those", "whoever", "anything", "everything", "more", "past",
"though", "whom", "are", "few", "most", "per", "though", "whose", "around", "following", 
"much", "plenty", "till", "will", "as", "for", "must", "plus", "to", "with", "at", 
"from", "my", "regarding", "toward", "within", "be", "have", "near", "same", "towards",
"without", "because", "he", "need", "several", "under", "worth", "before", "her",
"neither", "she", "unless", "would", "behind", "him", "no", "should", "unlike", "yes",
"below", "I", "nobody", "since", "until", "you", "beside", "if", "none".


